{
    "source": [
        "/workspace/scripts/train.py",
        "/workspace/zoo/extract_surface.py"
    ],
    "usage_instructions": "To compare NeuRodin with Neuralangelo on the Tanks and Temples dataset, follow these steps:\n\n1. First, train NeuRodin on the Barn scene from Tanks and Temples dataset using the two-stage approach:\n   ```bash\n   # Stage 1 - Train NeuRodin first stage on Barn (outdoor scene)\n   ns-train neurodin-stage1-outdoor-large --experiment_name neurodin-Barn-stage1 --pipeline.datamanager.eval_camera_res_scale_factor 0.5 tnt-data --data <path-to-tnt> --scene_name Barn\n   \n   # Stage 2 - Train NeuRodin second stage on Barn\n   ns-train neurodin-stage2-outdoor-large --experiment_name neurodin-Barn-stage2 --pipeline.datamanager.eval_camera_res_scale_factor 0.5 --trainer.load_dir <path-to-stage1-checkpoints-dir> tnt-data --data <path-to-tnt> --scene_name Barn\n   ```\n\n2. Train Neuralangelo on the same Barn scene:\n   ```bash\n   # Train Neuralangelo on Barn\n   ns-train neuralangelo --experiment_name neuralangelo-Barn --pipeline.datamanager.eval_camera_res_scale_factor 0.5 tnt-data --data <path-to-tnt> --scene_name Barn\n   ```\n\n3. Extract meshes from both models at resolution 2048 for fair comparison:\n   ```bash\n   # Extract NeuRodin mesh\n   python zoo/extract_surface.py --conf <path-to-neurodin-config> --resolution 2048\n   \n   # Extract Neuralangelo mesh\n   python zoo/extract_surface.py --conf <path-to-neuralangelo-config> --resolution 2048\n   ```\n\n4. Evaluate the meshes using the official Tanks and Temples evaluation script (not included in this repo, but referenced in the paper) to compute F-score, accuracy, completeness, precision, and recall.\n\n5. Visually inspect the structural integrity of the barn roof in both reconstructions.\n\n6. Compare parameter counts between the two models by examining the model configurations in the method_configs.py file. NeuRodin is designed to use approximately 1/8 fewer parameters than Neuralangelo."
}