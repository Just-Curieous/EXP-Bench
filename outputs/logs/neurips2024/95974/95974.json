{
    "questions": [
        {
            "hypothesis": "BeTopNet\u2019s topological formulations significantly improve interactive planning performance over existing planning systems in both hard and general driving scenarios.",
            "method": "Replicate the interactive planning experiments on the nuPlan dataset using the provided Test14 benchmarks and simulation protocols as described in the paper. Set up experiments for three different simulation scenarios: open-loop (OL) planning tests where the open-loop score (OLS) is computed using displacement and miss rate metrics; closed-loop non-reactive (CL-NR) simulations; and reactive (Test14-Inter) simulations. Use the same test splits (Test14-Hard, Test14-Random, and Test14-Inter) and follow the detailed evaluation protocol that measures metrics such as average planning score, driving safety (e.g., CA and TTC), driving progress, comfort, and compliance (e.g., DDC) as well as the aggregated PDMScore metric. The simulation environment should replicate the exact settings of the paper, including the multi-step reduction training strategy and evaluation procedures. Training should be performed on 4 NVIDIA A100 GPUs using the AdamW optimizer with a learning rate of 1e-4 and a multi-step reduction schedule. The planning model should be trained for 25 epochs with a batch size of 128, while the prediction module should be trained for 30 epochs with a batch size of 256. Document all percentage improvements compared to baseline methods\u2014these include learning-based, rule-based, and hybrid planners\u2014with reference to performance improvements observed in Tables 2 and 3 and qualitative results shown in Figures 7 to 10. For instance, the evaluation should capture improvements in closed-loop simulation scores (e.g., a CLS gain of approximately +4.6%), enhanced driving safety (e.g., +2.7% in CA and +1.0% in TTC), and better compliance (+2.8% in DDC) under hard-case scenarios, as well as consistent improvements in general cases.",
            "expected_outcome": "Experiments should demonstrate that BeTopNet achieves a statistically significant improvement over existing planning systems. Expected outcomes include a marked gain in performance metrics such as approximately +7.9% improvement in hard-case planning scores, around +6.2% improvement in closed-loop non-reactive simulation scores, and notable enhancements in reactive simulation scenarios. Detailed metrics should show improved values in driving safety (e.g., higher CA and TTC scores), driving progress, comfort, and compliance (e.g., higher DDC), thereby validating the hypothesis that the topological formulation of BeTopNet leads to superior interactive planning performance.",
            "subsection_source": "4.1 Main Result"
        },
        {
            "hypothesis": "BeTopNet provides enhanced marginal and joint motion prediction accuracy on the WOMD dataset compared to existing state-of-the-art methods without relying on model ensembles or extra data.",
            "method": "Implement the marginal and joint prediction experiments using the WOMD dataset following the leaderboard protocols. For marginal prediction, measure metrics including minADE, minFDE, Miss Rate, mAP, and Soft mAP as described in Table 4. For joint prediction, evaluate using similar metrics with a primary focus on mAP and Soft mAP as detailed in Table 5. Ensure that the experimental settings\u2014including data splits, scenario definitions, and evaluation metrics\u2014strictly adhere to those provided in the paper. Compare BeTopNet\u2019s performance with baselines such as TestReCoAt, HDGT, MTR/MTR++, MGTR, and recent game-theoretic approaches. Additionally, record and report the percentage improvements (for example, +2.7% to +3.4% improvement in mAP for marginal prediction and +4.1% improvement in mAP for joint prediction) to comprehensively assess the effectiveness of the proposed method. Include qualitative analyses from relevant figures, if available, to support the quantitative results.",
            "expected_outcome": "Results are expected to demonstrate that BeTopNet outperforms all baseline methods in key evaluation metrics such as mAP, Soft mAP, and minFDE. The improvements should confirm that the topological formulations coupled with local attention mechanisms offer robust performance gains in both marginal and joint prediction tasks. Detailed percentage improvements, as well as qualitative simulation results, will further establish the efficacy of the proposed approach.",
            "subsection_source": "4.1 Main Result"
        },
        {
            "hypothesis": "Does integrating BeTop as a synergistic objective with existing state-of-the-art (SOTA) planners and predictors improve planning and prediction performance on nuPlan and WOMD benchmarks?",
            "method": "a) For planning: Replicate the experiments on the nuPlan dataset using two baseline planners: PDM [69] and PlanTF [73]. Use the same hyperparameters, training configurations (e.g., 1M training cases with 8s horizon, as described in the paper), and evaluation protocols (including Test14-Random benchmark) to establish baseline planning scores such as OLS, CLS-NR, CLS, and average scores, along with additional safety metrics (CA, TTC, DDC). Reference quantitative results in Table 6 and Table 9 for detailed planning metrics. Then, augment each planner with the BeTop objective as described in the paper and compare the planning scores to assess performance improvements.\n\nb) For prediction: Using the WOMD dataset, replicate the experiments with two baseline predictors: MTR [22] and EDA [53]. Establish baseline metrics on the validation split including minADE, minFDE, Miss Rate, and mAP (and Soft-mAP if applicable), ensuring that data splits and evaluation protocols match those in the paper (e.g., using the same 20% partition of the WOMD train set for prediction experiments). Then, integrate BeTop into each predictor as detailed in the paper. Compare the performance changes by targeting reductions in prediction error measures and improvements in mAP. Additionally, consult Figures 9 and 10 for qualitative results demonstrating improvements in both joint and marginal prediction tasks.",
            "expected_outcome": "Based on reported results (e.g., in Table 6 and Table 7), it is expected that the addition of the BeTop objective will yield improved planning performance with approximately +2.1% improvement for learning-based planners and +2.0% for rule-based planners. In terms of prediction performance, improvements are anticipated in mAP (around +1.1% to +2.4%) along with reduced prediction errors (minADE, minFDE, and Miss Rate).",
            "subsection_source": "4.2 Ablation Study"
        },
        {
            "hypothesis": "Will varying the number of interactive agents (K) in the topology-guided local attention module affect the prediction mAP, and is there an optimal K beyond which performance degrades? We hypothesize that while increasing K initially improves mAP, there exists a tipping point (around K=32) after which additional agents lead to performance degradation.",
            "method": "Using the WOMD dataset (with the training partition defined in the paper and following the training configurations detailed in Section 4 and Appendix D), conduct a series of experiments by setting the number of future interactive agents (K) to a range of values (e.g., 4, 8, 16, 32, 64). For each K, train the BeTopNet model while keeping all other hyperparameters (optimizer, learning rate, batch size, etc.) constant. Evaluate each model using the same evaluation protocol as in the paper, measuring prediction mAP and other relevant metrics. Plot the resulting mAP against K to visualize the convergence behavior. Compare the outcomes with the trends presented in Figure 4 to verify the observed performance improvements and subsequent degradation.",
            "expected_outcome": "It is expected that increasing K will initially result in a steady improvement in the prediction mAP (with a maximum improvement of around +3.7%). However, beyond an optimal value (approximately K=32), the performance is anticipated to deteriorate (with a drop of approximately \u22121.8% in mAP) due to the inclusion of non-interactive agents, thus confirming the trend observed in Figure 4.",
            "subsection_source": "4.2 Ablation Study"
        },
        {
            "hypothesis": "Do the individual functionalities within BeTopNet\u2014specifically branched planning, cost learning, local attention, and encoder modules\u2014each contribute positively to its overall planning performance?",
            "method": "Perform an ablation study on the nuPlan dataset using the Test14 benchmarks (including both Test14-Hard and Test14-Random setups). First, replicate the full BeTopNet model under the established training and evaluation settings (e.g., 1M training cases, 8s horizon, 25 epochs with a batch size of 128 for planning). Then, create several variants by disabling one or more components: (1) No branched planning, (2) No cost learning, (3) Sole BeTop configuration using only imitative learning, (4) No local attention, and (5) Using encoder modules only. For each model variant, measure the planning performance metrics, including the open-loop score (OLS) and closed-loop simulation metrics (CLS and CLS-NR), which aggregate statistics on driving safety, planning progress, ride comfort, and rule compliance. Also, refer to the reference values reported in Table 8 for the full model performance. Ensure that all other experimental settings, such as data splits, simulation parameters, horizon length, and computational resources, remain constant across experiments. Document additional details by comparing the trends in performance degradation with respect to the full model, and, where available, cross-check with qualitative simulation outputs (e.g., as suggested by Figures 7 and 8) for closed-loop performance consistency.",
            "expected_outcome": "The full BeTopNet model is expected to exhibit the best overall performance. Each component should show a positive contribution, such that ablating any one (or more) of the key modules leads to a measurable degradation in planning performance. For example, the removal of cost learning is anticipated to result in approximately a 2.9% drop in CLS, while disabling branched planning or local attention should similarly reduce performance metrics. This systematic drop across different ablations will verify that the individual functions of branched planning, cost learning, local attention, and encoder modules each contribute to the robustness of BeTopNet's planning capability.",
            "subsection_source": "4.2 Ablation Study"
        }
    ],
    "follow_up_work_ideas": [
        {
            "idea": "Extend the evaluation of BeTopNet\u2019s planning performance to more diverse and dynamic urban driving datasets.",
            "experiment_design": "Collect or utilize additional urban driving datasets with varying environmental conditions and scenarios. Replicate the interactive planning experiments under similar testing protocols while introducing variations such as adverse weather or unexpected obstacles. Compare performance metrics against the current results to assess the robustness and generalizability of BeTopNet\u2019s planning capabilities.",
            "subsection_source": "4.1 Main Result"
        },
        {
            "idea": "Investigate the impact of computational resource variations and hyperparameter tuning on the prediction accuracy and planning robustness of BeTopNet.",
            "experiment_design": "Perform a controlled study where the model is trained and evaluated under different compute resource configurations (e.g., varying GPU/CPU setups, memory limits) and different hyperparameter settings (e.g., learning rate, optimizer type). Analyze the influence of these factors on the key metrics for both planning and prediction tasks. This follow-up work would verify the sensitivity of BeTopNet to system configurations and guide optimal deployment strategies.",
            "subsection_source": "4.1 Main Result"
        },
        {
            "idea": "Dynamic Selection of Interactive Agents: Investigate if an adaptive mechanism can dynamically select the optimal number of interactive agents (K) during inference rather than using a fixed value.",
            "experiment_design": "Develop a framework where the model estimates the appropriate K based on scene complexity or interaction level. Train the model on the WOMD dataset with this dynamic module and evaluate performance against the static K baseline. Compare mAP across a range of scenarios and analyze if the dynamic selection improves overall prediction reliability and efficiency.",
            "subsection_source": "4.2 Ablation Study"
        },
        {
            "idea": "Extended Ablation Study Across Different Scenarios: Examine whether the contributions of individual BeTopNet components vary across diverse driving scenarios (e.g., dense urban vs. suburban conditions).",
            "experiment_design": "Partition the nuPlan and WOMD datasets into distinct subsets based on scenario characteristics. Perform ablation studies (similar to the current experiment) within each scenario subset. Evaluate planning and prediction metrics for each configuration and analyze if certain components (e.g., cost learning or local attention) are more effective in complex urban scenarios compared to simpler environments.",
            "subsection_source": "4.2 Ablation Study"
        }
    ],
    "main_takeaways": [
        "The paper provides a fully reproducible experimental setup with detailed descriptions of compute resources, training/test splits, and hyperparameter configurations, facilitating easy reproduction of results.",
        "Experimental results are backed by both empirical validations (through official leaderboards and comprehensive figures/tables) and theoretical proofs, ensuring the robustness of the main claims.",
        "The authors have taken care to report asymmetric error bars correctly and documented the methodology in extensive appendices, enhancing transparency and reproducibility.",
        "The paper demonstrates that the proposed method achieves competitive performance compared to existing baselines, as evidenced by quantitative results reported in Section 4.1 and supported by detailed experiments.",
        "Supplementary materials (Appendices B, C, and D) provide additional technical depth, including full analytical proofs and detailed experiment configurations (e.g., compute resources, hyperparameters, and model architecture details)."
    ]
}