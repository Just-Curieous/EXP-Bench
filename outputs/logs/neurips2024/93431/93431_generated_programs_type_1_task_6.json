{
    "source": ["/workspace/docs/examples/robotics/metaworld.ipynb"],
    "usage_instructions": "1. Install the required dependencies: `pip install trace-opt` and `pip install -e LLF-Bench/.[metaworld]` (after cloning the LLF-Bench repository).\n2. Set up your OpenAI API key in the notebook.\n3. Modify the `optimize_policy` function to compare the three optimizers:\n   - For Trace (OptoPrime with memory): Use `optimizer = OptoPrime(controller.parameters(), config_list=config_list, memory_size=5)`\n   - For Trace NoMem (OptoPrime without memory): Use `optimizer = OptoPrime(controller.parameters(), config_list=config_list, memory_size=0)`\n   - For OPRO: Use `optimizer = OPRO(controller.parameters(), config_list=config_list)`\n4. Run the notebook with each of the three Meta-World tasks by changing the `env_name` parameter in the `optimize_policy` call:\n   - For Reach: `env_name=\"llf-metaworld-reach-v2\"`\n   - For Pick-place: `env_name=\"llf-metaworld-pick-place-v2\"`\n   - For Push: `env_name=\"llf-metaworld-push-v2\"`\n5. Compare the performance metrics (success rate and returns) across the three optimizers and three tasks."
}