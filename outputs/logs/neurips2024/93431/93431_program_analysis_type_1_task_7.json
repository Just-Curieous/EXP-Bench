{
  "requirements": [
    "Step 1: Set up the environment by importing necessary libraries including textgrad, opto, numpy, argparse, concurrent.futures, and tqdm (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:3-17, /workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:3-17)",
    "Step 2: Define command-line arguments for configuring the experiment, including algorithm selection, task selection, model engines, and optimization parameters (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:32-41, /workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:23-35)",
    "Step 3: Initialize the language model engines for evaluation and optimization (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:226-227, /workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:89-92)",
    "Step 4: Load the task dataset (training, validation, and test sets) (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:228, /workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:95-96)",
    "Step 5: For solution optimization: Implement a function to get zero-shot answers from the LLM (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:60-71)",
    "Step 6: For solution optimization: Implement a majority voting ensemble method to combine multiple predictions (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:44-57)",
    "Step 7: For solution optimization: Implement the test-time training function that optimizes the solution using either TextGrad or Trace's optimizers (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:74-120, /workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:142-210)",
    "Step 8: For prompt optimization: Implement functions to evaluate samples and datasets (/workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:39-72)",
    "Step 9: For prompt optimization: Set up the system prompt as a trainable node and initialize the optimizer based on the selected algorithm (/workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:103-122)",
    "Step 10: For prompt optimization: Implement the training loop that optimizes the system prompt over multiple epochs (/workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:156-209)",
    "Step 11: Process results by calculating mean performance, standard errors, and execution times (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:253-260, /workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:212-213)",
    "Final Step: Save the results to JSON files in the textgrad_figures directory (/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py:265-274, /workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py:216-220)"
  ],
  "agent_instructions": "Your task is to implement two scripts that compare different optimization methods from the TextGrad paper:\n\n1. Solution Optimization Script:\n   - Create a script that optimizes solutions for multiple-choice questions using different optimization algorithms.\n   - The script should compare TextGrad and Trace's optimization methods (OptoPrime and OptoPrimeMulti).\n   - Implement a workflow that:\n     - Loads a task dataset (default: MMLU_machine_learning)\n     - Gets zero-shot answers from an LLM\n     - Applies optimization algorithms to improve the answers\n     - Uses majority voting for ensemble predictions\n     - Evaluates and compares performance\n     - Saves results to JSON files\n\n2. Prompt Optimization Script:\n   - Create a script that optimizes prompts for tasks rather than solutions.\n   - The script should compare TextGrad and Trace's OptoPrime optimizer.\n   - Implement a workflow that:\n     - Loads a task dataset (default: BBH_object_counting)\n     - Evaluates zero-shot performance\n     - Optimizes the system prompt over multiple epochs\n     - Evaluates on validation and test sets\n     - Saves results to JSON files\n\nBoth scripts should:\n- Accept command-line arguments for algorithm selection, task selection, and model engines\n- Use concurrent execution for efficient evaluation\n- Calculate and report performance metrics\n- Save results in a 'textgrad_figures' directory\n\nThe TextGrad library should be installed using 'pip install textgrad' before running the scripts.",
  "masked_source": [
    "/workspace/examples/textgrad_examples/evals/textgrad_solution_optimization.py",
    "/workspace/examples/textgrad_examples/evals/textgrad_prompt_optimization.py"
  ]
}