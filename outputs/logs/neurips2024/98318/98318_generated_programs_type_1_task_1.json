{
    "source": ["/workspace/benchmarl/run.py"],
    "usage_instructions": "To test whether increasing the number of training timesteps beyond 1e7 further improves the normalized return for actor-critic based algorithms on VMAS tasks, run the following command:\n\npython benchmarl/run.py -m algorithm=mappo,maddpg,masac task=vmas/balance,vmas/sampling,vmas/navigation experiment.max_n_frames=20000000 seed=0,1,2,3,4\n\nThis command will run the three actor-critic algorithms (MAPPO, MADDPG, MASAC) on the three VMAS tasks (Balance, Sampling, Navigation) with 5 different random seeds, extending the training to 2e7 timesteps (double the original 1e7 timesteps used in the fine-tuned VMAS configuration). The results can be compared with the original BenchMARL experiments to determine if increasing the number of training timesteps beyond 1e7 further improves the normalized return.\n\nTo run with even more timesteps (e.g., 5e7), simply modify the max_n_frames parameter:\n\npython benchmarl/run.py -m algorithm=mappo,maddpg,masac task=vmas/balance,vmas/sampling,vmas/navigation experiment.max_n_frames=50000000 seed=0,1,2,3,4\n\nAfter running the experiments, you can use the evaluation and plotting tools provided by BenchMARL to analyze the results:\n\n1. The normalized return curves will be automatically generated and can be viewed through the configured loggers (e.g., WandB).\n2. To generate performance profiles and compare with the original results, you can use the plotting functionality in BenchMARL's eval_results.py."
}