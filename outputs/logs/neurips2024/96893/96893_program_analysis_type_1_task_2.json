{
  "requirements": [
    "Step 1: Load and parse command line arguments including the path to the checkpoint, work directory, and demo configuration file (/workspace/inference_demo.py:13-26)",
    "Step 2: Define a function to calculate Dice score between predictions and ground truth labels (/workspace/inference_demo.py:28-45)",
    "Step 3: Implement the zoom-in-zoom-out inference mechanism that first performs global inference on a resized image and then refines the prediction on a cropped region of interest (/workspace/inference_demo.py:47-155)",
    "Step 4: Create a function to process a single CT scan by loading the image and ground truth, performing inference, and visualizing the results (/workspace/inference_demo.py:157-173)",
    "Step 5: Set up the SegVol model by loading the SAM model and checkpoint (/workspace/inference_demo.py:175-197)",
    "Step 6: Load the demo configuration with paths to CT scan, ground truth segmentation, and organ categories (/workspace/inference_demo.py:199-202)",
    "Step 7: Preprocess the CT and ground truth data by applying transformations like normalization and resizing (/workspace/data_process/demo_data_process.py:49-106)",
    "Step 8: Configure the inference parameters for prompts (text, box, point) and zoom-in-zoom-out mechanism (/workspace/inference_demo.py:207-212)",
    "Step 9: Run inference on the CT scan and measure performance metrics (/workspace/inference_demo.py:214)",
    "Step 10: Implement sliding window inference for processing large 3D volumes in patches (/workspace/utils/monai_inferers_utils.py:71-296)",
    "Step 11: Generate bounding boxes from segmentation masks to use as prompts (/workspace/utils/monai_inferers_utils.py:365-402)",
    "Step 12: Select points from segmentation masks to use as prompts (/workspace/utils/monai_inferers_utils.py:405-446)",
    "Step 13: Visualize the segmentation results by showing the original image, ground truth, and predictions (/workspace/utils/visualize.py:8-73)",
    "Final Step: Compare the performance of the three approaches (simple resize, sliding window, zoom-out-zoom-in) by running the script with different configurations and analyzing the Dice scores and inference times (/workspace/inference_demo.py:216-218)"
  ],
  "agent_instructions": "Your task is to implement a medical image segmentation system that can segment organs in 3D CT scans using a SegVol model (based on the Segment Anything Model architecture). The system should support three different inference strategies that you'll need to compare:\n\n1. A simple resize strategy that directly processes the entire volume at a lower resolution\n2. A sliding window approach that processes the volume in patches\n3. A zoom-out-zoom-in mechanism that first identifies regions of interest at low resolution and then refines them at high resolution\n\nYou need to create:\n\n1. A main inference script that:\n   - Loads a pretrained SegVol model\n   - Processes CT scans and their ground truth segmentations\n   - Implements the three inference strategies\n   - Calculates Dice scores to evaluate segmentation quality\n   - Visualizes the results\n\n2. A configuration file for specifying:\n   - Paths to CT scans and ground truth segmentations\n   - A list of organ categories to segment (liver, kidney, spleen, pancreas, etc.)\n\n3. A shell script to run the inference with appropriate parameters\n\nThe system should support different types of prompts for the segmentation model:\n- Text prompts (organ names)\n- Bounding box prompts\n- Point prompts\n\nFor the zoom-out-zoom-in mechanism, implement a two-stage process where:\n1. First, perform inference on a downsampled version of the volume\n2. Then, identify regions of interest and perform high-resolution inference only on those regions\n\nInclude utility functions for:\n- Calculating Dice scores between predictions and ground truth\n- Generating bounding boxes from segmentation masks\n- Selecting points from segmentation masks\n- Visualizing the segmentation results\n\nThe final output should display the Dice scores for each organ and inference strategy, allowing comparison of the three approaches.",
  "masked_source": [
    "/workspace/inference_demo.py",
    "/workspace/script/inference_demo.sh",
    "/workspace/config/config_demo.json",
    "/workspace/data_process/demo_data_process.py",
    "/workspace/utils/monai_inferers_utils.py",
    "/workspace/utils/visualize.py"
  ]
}