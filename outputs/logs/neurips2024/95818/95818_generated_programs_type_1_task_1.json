{
    "source": ["/workspace/train_combo.sh", "/workspace/opencls/configs/cls_schedule/cls_vit_l16_s512m_bs16k.yaml", "/workspace/opencls/configs/cls_schedule/lit_vit_l16_s512m_bs16k.yaml"], 
    "usage_instructions": "1. First, modify the DATA_PATH and VAL_DATA_PATH in train_combo.sh to point to your Datacomp-1B dataset and ImageNet-1K validation set paths.\n2. Execute the script with the SuperClass ViT-L/16 configuration files: `bash train_combo.sh configs/cls_schedule/cls_vit_l16_s512m_bs16k.yaml configs/cls_schedule/lit_vit_l16_s512m_bs16k.yaml opencls`\n3. The script will first train the SuperClass model using cls_vit_l16_s512m_bs16k.yaml and then perform lock-image tuning using lit_vit_l16_s512m_bs16k.yaml.\n4. During the LiT phase, zero-shot evaluation on ImageNet-1K will be performed automatically as specified in the lit_vit_l16_s512m_bs16k.yaml configuration (zeroshot_steps: 6104).\n5. The results will show the zero-shot classification accuracy of SuperClass ViT-L/16 on ImageNet-1K, which can be compared with the reported results for OpenAI CLIP ViT-L/14 (75.3%) and OpenCLIP ViT-L/14 (79.2%)."
}