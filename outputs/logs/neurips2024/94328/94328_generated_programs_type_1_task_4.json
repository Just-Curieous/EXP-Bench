{
    "source": ["/workspace/fake_quant/main.py"],
    "usage_instructions": "Execute the main.py script with different configurations to compare QuaRot vs traditional quantization methods at low bit precision. For the experiment comparing RTN, GPTQ, QuaRot-RTN, and QuaRot-GPTQ at different weight precisions (2-4 bits), use the following commands:\n\n1. For RTN (traditional round-to-nearest):\n   ```\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-7b-hf --w_bits 4 --w_rtn\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-13b-hf --w_bits 4 --w_rtn\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-70b-hf --w_bits 4 --w_rtn\n   ```\n   Repeat with --w_bits 3 and --w_bits 2 for each model.\n\n2. For GPTQ (error-minimizing quantization):\n   ```\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-7b-hf --w_bits 4\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-13b-hf --w_bits 4\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-70b-hf --w_bits 4\n   ```\n   Repeat with --w_bits 3 and --w_bits 2 for each model.\n\n3. For QuaRot-RTN (RTN with Hadamard transformation):\n   ```\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-7b-hf --w_bits 4 --w_rtn --rotate\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-13b-hf --w_bits 4 --w_rtn --rotate\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-70b-hf --w_bits 4 --w_rtn --rotate\n   ```\n   Repeat with --w_bits 3 and --w_bits 2 for each model.\n\n4. For QuaRot-GPTQ (GPTQ with Hadamard transformation):\n   ```\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-7b-hf --w_bits 4 --rotate\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-13b-hf --w_bits 4 --rotate\n   python /workspace/fake_quant/main.py --model meta-llama/Llama-2-70b-hf --w_bits 4 --rotate\n   ```\n   Repeat with --w_bits 3 and --w_bits 2 for each model.\n\nThe script will automatically evaluate perplexity on WikiText-2 dataset and report the results, which can be compared to see how QuaRot improves quantization quality at low bit precision."
}