[
  {
    "mode": "A",
    "question": "How can you run a demo of WorkArena-L1 atomic tasks and observe the automated solutions?",
    "method": "Create a script that uses the BrowserGym environment to run through a sample of WorkArena-L1 atomic tasks, using the cheat function to automatically solve them and display the results.",
    "expected_outcome": "A successful run of multiple WorkArena-L1 tasks with automated solutions and validation of the results, showing success messages for each task.",
    "source": ["/workspace/README.md"],
    "usage_instructions": "1. Import the necessary modules: random, BrowserEnv from browsergym.core.env, ATOMIC_TASKS from browsergym.workarena, and sleep from time.\n2. Shuffle the ATOMIC_TASKS list to get a random order of tasks.\n3. Loop through a subset of tasks (limit to 3-5 tasks for demonstration).\n4. For each task, instantiate a BrowserEnv with the task_entrypoint and headless=False to make the browser visible.\n5. Reset the environment to initialize it.\n6. Add an initial assistant message to the chat indicating work is starting.\n7. Create an empty list to store cheat messages.\n8. Call the task's cheat function with the page and cheat_messages list.\n9. Add each cheat message to the chat.\n10. Add a completion message to the chat.\n11. Validate the solution using the task's validate function.\n12. Add appropriate user feedback based on the validation result.\n13. Wait a few seconds between tasks.\n14. Close the environment before moving to the next task."
  },
  {
    "mode": "A",
    "question": "How can you run a demo of WorkArena-L2 compositional tasks that require multiple steps to complete?",
    "method": "Create a script that uses the BrowserGym environment to run through a sample of WorkArena-L2 compositional tasks, using the cheat function to automatically solve each subtask and validate the results.",
    "expected_outcome": "A successful run of multiple WorkArena-L2 compositional tasks with automated solutions for each subtask and validation of the overall results, showing success messages for each task.",
    "source": ["/workspace/README.md"],
    "usage_instructions": "1. Import the necessary modules: random, BrowserEnv from browsergym.core.env, get_all_tasks_agents from browsergym.workarena, and sleep from time.\n2. Get a sample set of L2 tasks using get_all_tasks_agents(filter=\"l2\").\n3. Extract the tasks and seeds from the sampled set.\n4. Loop through a subset of tasks and their corresponding seeds (limit to 2-3 tasks for demonstration).\n5. For each task, instantiate a BrowserEnv with the task_entrypoint and headless=False to make the browser visible.\n6. Reset the environment to initialize it.\n7. Add an initial assistant message to the chat indicating work is starting.\n8. Loop through each subtask using range(len(env.task)).\n9. For each subtask, call the task's cheat function with the page, chat_messages, and subtask_idx.\n10. Wait a second between subtasks.\n11. Validate the solution after all subtasks are completed.\n12. Add appropriate user feedback based on the validation result.\n13. Wait a few seconds between tasks.\n14. Close the environment before moving to the next task."
  },
  {
    "mode": "B",
    "question": "How can you generate a knowledge base of company facts with corresponding articles and questions?",
    "method": "Create a script that generates knowledge base articles for a list of company facts, creates questions to query those articles, and validates that the questions can be answered correctly from the articles.",
    "expected_outcome": "A JSON file containing a knowledge base with facts, articles, questions, and alternative answer formulations for each fact.",
    "source": ["/workspace/scripts/generate_knowledge_base.ipynb", "/workspace/generate_knowledge_base.ipynb"],
    "usage_instructions": "1. Import the necessary modules: json, openai, os, and concurrent.futures.\n2. Set up the OpenAI client using an API key from environment variables.\n3. Create a chat function that sends messages to the OpenAI API and returns the response.\n4. Implement the generate_article function that:\n   a. Takes an item, value, and list of all facts as input\n   b. Creates a prompt for the LLM to generate an article containing the fact\n   c. Validates that the article contains the exact fact\n   d. Returns the cleaned article text\n5. Define a list of company facts, each with an 'item' and 'value' field.\n6. For each fact, generate an article using the generate_article function.\n7. Implement the generate_question function that:\n   a. Takes an article, item, value, and number of questions as input\n   b. Creates a prompt for the LLM to generate questions about the fact\n   c. Validates that the questions can be answered correctly using the is_question_answerable function\n   d. Returns a list of valid questions\n8. Implement the is_question_answerable function that:\n   a. Takes an article, question, and expected value as input\n   b. Tests if the question can be answered correctly from the article\n   c. Returns whether the question is answerable and any incorrect answers\n9. For each fact with its article, generate questions using the generate_question function.\n10. Implement the alternative_answers function that generates different ways to express the same answer.\n11. For each fact with its article and questions, generate alternative answers.\n12. Save the complete knowledge base to a JSON file."
  }
]