{
  "requirements": [
    "Step 1: Import the run_exp function from the llmtuner module (/workspace/llama-alpaca/src/train_bash.py:1-1)",
    "Step 2: Define a main function that calls run_exp to start the fine-tuning process (/workspace/llama-alpaca/src/train_bash.py:4-5)",
    "Step 3: Parse command line arguments including model name, dataset, finetuning type, and hyperparameters (/workspace/llama-alpaca/src/llmtuner/tuner/tune.py:19-20)",
    "Step 4: Load and prepare the dataset for training (/workspace/llama-alpaca/src/llmtuner/tuner/sft/workflow.py:30-36)",
    "Step 5: Load the pre-trained language model and tokenizer (/workspace/llama-alpaca/src/llmtuner/tuner/sft/workflow.py:34-35)",
    "Step 6: Initialize the appropriate fine-tuning method based on the finetuning_type parameter (/workspace/llama-alpaca/src/llmtuner/tuner/core/adapter.py:24-97)",
    "Step 7: For block-wise fine-tuning (BAdam), create a BlockOptimizer that wraps the base optimizer (/workspace/llama-alpaca/src/llmtuner/tuner/sft/trainer.py:234-241)",
    "Step 8: Set up the BlockOptimizer to update only a subset of model parameters at each step (/workspace/llama-alpaca/src/llmtuner/tuner/sft/block_optim.py:60-137)",
    "Step 9: Implement the parameter switching strategy (random, ascending, or descending) to rotate through different blocks (/workspace/llama-alpaca/src/llmtuner/tuner/sft/block_optim.py:323-336)",
    "Step 10: Execute the training loop, updating only the active block of parameters at each step (/workspace/llama-alpaca/src/llmtuner/tuner/sft/block_optim.py:212-224)",
    "Step 11: Periodically switch to a different block of parameters based on the switch_block_every parameter (/workspace/llama-alpaca/src/llmtuner/tuner/sft/block_optim.py:223-224)",
    "Step 12: Save the fine-tuned model and training metrics (/workspace/llama-alpaca/src/llmtuner/tuner/sft/workflow.py:71-77)"
  ],
  "agent_instructions": "Your task is to implement a script for fine-tuning large language models (LLMs) using a block-wise optimization technique. This technique, which we'll call BAdam, updates only a subset of the model's parameters at each optimization step and rotates through different blocks of parameters over time.\n\nYou need to create a training script that:\n\n1. Accepts command-line arguments for model configuration, dataset selection, and training hyperparameters\n2. Supports fine-tuning Llama models (both Llama 2 and Llama 3) on instruction datasets\n3. Implements the block-wise optimization strategy with the following features:\n   - Divides the model parameters into blocks (typically by layers)\n   - Updates only one block of parameters at each optimization step\n   - Rotates through different blocks using configurable strategies (random, ascending, or descending order)\n   - Allows setting how frequently to switch between blocks\n4. Supports comparison with other fine-tuning methods like full parameter fine-tuning, LoRA, and sparse fine-tuning\n\nThe script should be able to run commands like:\n```bash\npython train_script.py \\\n    --stage sft \\\n    --model_name_or_path meta-llama/Llama-2-7b-hf \\\n    --do_train \\\n    --dataset alpaca_gpt4_en \\\n    --template default \\\n    --finetuning_type block \\\n    --output_dir ./outputs/llama2-7b-badam-1e-5 \\\n    --overwrite_cache \\\n    --per_device_train_batch_size 2 \\\n    --gradient_accumulation_steps 8 \\\n    --learning_rate 1e-5 \\\n    --num_train_epochs 3 \\\n    --switch_block_every 100 \\\n    --switch_mode random \\\n    --bf16 True\n```\n\nThe implementation should be efficient and handle gradient checkpointing appropriately to manage memory usage during training.",
  "masked_source": [
    "/workspace/llama-alpaca/src/train_bash.py",
    "/workspace/llama-alpaca/src/llmtuner/tuner/tune.py",
    "/workspace/llama-alpaca/src/llmtuner/tuner/sft/workflow.py",
    "/workspace/llama-alpaca/src/llmtuner/tuner/sft/block_optim.py",
    "/workspace/llama-alpaca/src/llmtuner/tuner/sft/trainer.py",
    "/workspace/llama-alpaca/src/llmtuner/tuner/core/adapter.py",
    "/workspace/llama-alpaca/src/llmtuner/tuner/core/utils.py",
    "/workspace/llama-alpaca/src/llmtuner/hparams/finetuning_args.py"
  ]
}