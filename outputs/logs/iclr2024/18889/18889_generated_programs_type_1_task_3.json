{
    "source": [
        "/workspace/opencood/tools/profiler/params_calc_multi.py",
        "/workspace/opencood/tools/profiler/params_flops_multi.py",
        "/workspace/opencood/tools/profiler/traintp_calc.py",
        "/workspace/opencood/tools/inference_heter_in_order.py"
    ],
    "usage_instructions": "To evaluate HEAL's Pyramid Fusion and backward alignment modules on the OPV2V-H dataset, follow these steps:\n\n1. First, train the HEAL model following the instructions in the README (sections 'HEAL's Train Command' steps 1-3).\n\n2. After training, measure the model parameters, FLOPs, and memory usage using:\n   ```\n   python opencood/tools/profiler/params_calc_multi.py --hypes_yaml /path/to/HEAL/config.yaml\n   python opencood/tools/profiler/params_flops_multi.py --hypes_yaml /path/to/HEAL/config.yaml\n   python opencood/tools/profiler/traintp_calc.py --hypes_yaml /path/to/HEAL/config.yaml\n   ```\n   These scripts will output metrics for model parameters (in millions), FLOPs (in tera operations), and peak memory usage (in GB).\n\n3. Run the same profiling scripts on baseline models (Late Fusion, HM-ViT) for comparison.\n\n4. Finally, evaluate the detection performance using:\n   ```\n   python opencood/tools/inference_heter_in_order.py --model_dir /path/to/HEAL/final_infer\n   ```\n   This will evaluate HEAL's performance in an incremental agent integration scenario using the OPV2V-H dataset, reporting AP50 and AP70 metrics.\n\n5. Compare the results to determine if HEAL achieves competitive or superior detection performance with reduced computational costs compared to baseline methods."
}