{
    "questions": [
        {
            "hypothesis": "Does the choice of aggregation degrees in the LNAMD module affect the classification and segmentation performance on MVTec AD and VisA datasets, particularly considering that larger aggregation degrees may benefit the segmentation of large anomalies (as in MVTec AD) while smaller degrees may be more effective for small anomalies (as in VisA)?",
            "method": "Conduct an ablation study by varying the aggregation degree settings for the LNAMD module. Specifically, test the following configurations: {1}, {3}, {5}, {1,3}, {3,5}, and {1,3,5} on both the MVTec AD and VisA datasets. For each configuration, compute the image-level anomaly detection (AC) and pixel-level anomaly segmentation (AS) metrics, measured in AUROC percentages. Use the same pre-processing steps, backbone (ViT-L/14-336 pre-trained by OpenAI), and evaluation protocols as described in the paper. In addition to quantitative analysis, qualitatively review the segmentation outputs as displayed in Figures 11 to 16. Compare performance across configurations to not only determine the most effective aggregation degree setting but also to understand how aggregation degree impacts performance based on anomaly size\u2014anticipating that larger degrees work better on MVTec AD (which exhibits larger anomalies) and smaller degrees on VisA (characterized by smaller anomalies).",
            "expected_outcome": "Based on the results shown in Table 3 and related qualitative figures, the expected optimal configuration is {1,3,5}. This combination is anticipated to achieve an AC of approximately 97.8% and an AS of around 97.3% on MVTec AD, with comparable improvements on VisA (AC around 92.8% and AS near 98.7%). This would validate that combining multiple aggregation degrees enhances both classification and segmentation performance compared to using a single aggregation degree.",
            "subsection_source": "4.1 QUANTITATIVE AND QUALITATIVE RESULTS"
        },
        {
            "hypothesis": "Does the selection of different sample strategies in the MSM module influence the overall anomaly detection performance?",
            "method": "Perform an ablation study on the MSM module to assess the impact of various sample strategies on overall anomaly detection. The strategies include: (1) using the minimum anomaly score, (2) maximum anomaly score, (3) mean anomaly score, and (4) hybrid approaches such as '30% + min', '30% + max', and '30% + mean'. For each strategy, compute the image-level AUROC (AC) and pixel-level AUROC (AS) on both the MVTec AD and VisA datasets. All other experimental settings (e.g., using the same backbone, image resolution, and pre-processing steps) will remain unchanged. Moreover, incorporate an interval average operation on the minimum 30% of the anomaly scores in the MSM module to address the issue of normal patches with few similar matches. This operation, which is illustrated in Fig. 4 and Fig. 10, aims to reduce the influence of dissimilar patches in the scoring.",
            "expected_outcome": "According to Table 4 and supporting quantitative analyses, it is expected that the '30% + mean' strategy will yield superior performance. Specifically, the anticipated results are image-AUROC and pixel-AUROC values that match the best overall configuration (e.g., approximately 97.8% AC and 97.3% AS on MVTec AD, and around 92.8% AC and 98.7% AS on VisA). This would indicate that combining a minimum percentage (30%) with the mean statistic leads to a more robust anomaly score estimation compared to using single measures.",
            "subsection_source": "4.1 QUANTITATIVE AND QUALITATIVE RESULTS"
        },
        {
            "hypothesis": "Does the integration of the RsCIN module enhance the anomaly classification performance on industrial datasets?",
            "method": "Conduct controlled experiments to compare the performance of the MuSc model with and without the RsCIN module. Use the MVTec AD and VisA datasets to measure classification metrics such as AUROC, F1-max, and AP. Implement two sets of experiments: one with the RsCIN module enabled and one with it disabled, keeping all other parameters (e.g., backbone, pre-processing, and anomaly scoring modules) constant. Evaluate the performance differences with statistical significance if possible.",
            "expected_outcome": "Based on the findings in Table 5, the experiments with the RsCIN module are expected to show improved classification performance. For example, on MVTec AD, inclusion of RsCIN should elevate AUROC, F1-max, and AP scores compared to the configuration without it, thereby confirming its contribution to a more refined anomaly detection process.",
            "subsection_source": "4.1 Q UANTITATIVE AND QUALITATIVE RESULTS"
        },
        {
            "hypothesis": "Does the zero-shot MuSc method outperform existing zero/few-shot and many-shot methods on industrial anomaly detection tasks?",
            "method": "Perform a comprehensive comparative analysis by evaluating the zero-shot MuSc method alongside several state-of-the-art zero/few-shot methods (e.g., WinCLIP, APRIL-GAN, RegAD, GraphCore) as well as representative many-shot methods (e.g., CutPaste, IGD) on the MVTec AD and VisA datasets. Use identical evaluation metrics across methods, including image-level metrics (AUROC, F1-max, AP) and pixel-level segmentation metrics (AUROC, F1-max, AP, PRO). Ensure that the experimental setup remains consistent for all methods by using the same pre-trained backbone and image resolution. Additionally, assess the inference efficiency by dividing the test set into subsets (referencing Tables 6 and 7) to analyze per-image inference time and maximum GPU memory cost under different subset sizes. Compile the results into detailed tables (e.g., Tables 1, 2, 16, and 17 for category-wise analyses) and conduct a statistical analysis of the relative improvements achieved by MuSc over competing methods.",
            "expected_outcome": "MuSc is expected to demonstrate a significant improvement in performance metrics over existing zero-shot and few-shot methods while maintaining competitive or superior results compared to many-shot methods. For instance, based on prior results, MuSc should achieve notable gains such as a 21.9% improvement in AP over the second-best zero-shot method on the MVTec AD dataset. Moreover, it is anticipated that MuSc will report high classification AUROC values (e.g., around 97.8% for classification on MVTec AD) and perform robustly on segmentation tasks (e.g., achieving segmentation AUROC values of roughly 98.8%). Efficiency improvements are also expected, with reduced inference time and lower GPU memory usage when test images are processed in smaller subsets, as highlighted in Tables 6 and 7. These findings will reinforce that MuSc achieves competitive anomaly detection performance without using any labeled images.",
            "subsection_source": "4.1 QUANTITATIVE AND QUALITATIVE RESULTS"
        },
        {
            "hypothesis": "Does the choice of aggregation degree (r) in the LNAMD module impact the comprehensive anomaly classification (AC) and segmentation (AS) performance differently on datasets with small versus large abnormal regions?",
            "method": "Perform controlled experiments by varying the aggregation degree r. Specifically, run the anomaly detection pipeline on two datasets (MVTec AD, which has larger anomaly regions, and VisA, which has smaller anomalies) using different r values (e.g., r = 1, 3, 5 individually and in combination). Record AC and AS metrics for each configuration. Compare the experimental results to evaluate if smaller r values favor small anomaly regions (as anticipated on VisA) while larger r values excel for large anomalies (as observed on MVTec AD). Use the same pre-trained ViT-L/14-336 backbone and identical preprocessing steps to ensure fairness.",
            "expected_outcome": "It is expected that a combination using all three aggregation degrees (r \u2208 {1,3,5}) will yield better overall AC and AS results. Additionally, smaller r should perform better on VisA while larger r should benefit MVTec AD, confirming the trade-off based on anomaly size.",
            "subsection_source": "4.2 A BLATION STUDY"
        },
        {
            "hypothesis": "Does the proportion of the minimum value interval selection in the Mutual Scoring Module (MSM) affect anomaly detection performance (AC and AS), and is 30% the optimal choice?",
            "method": "Set up an ablation study by varying the percentage of the minimum value interval used in the MSM from 10% to 100% (e.g., test at 10%, 30%, 50%, 70%, 90%, and 100%). For each setting, run the MuSc pipeline on both the MVTec AD and VisA datasets using consistent train/test splits. Record detailed performance metrics: image-level AUROC for classification (AC) and pixel-level AUROC for segmentation (AS). In addition to plotting the performance trends as in Fig. 7, annotate the plots with the exact AUROC values (e.g., as observed in Table 7 for varied subset sizes) and perform statistical significance tests where applicable. Also, document any variations in anomaly score distributions caused by the interval average operation on normal patches. This comprehensive analysis will help determine which minimum value interval percentage offers the best trade-off for both datasets.",
            "expected_outcome": "Based on prior results, selecting the minimum 30% value interval is expected to yield the best or near-optimal overall performance in both AC and AS. Deviations from this setting are anticipated to lead to a degradation in performance, as evidenced by the trends shown in Fig. 7. Detailed documentation of AUROC trends across the different interval percentages should confirm that 30% is optimal for balancing the interval averaging effect on normal patch scoring.",
            "subsection_source": "4.2 A BLATION STUDY"
        },
        {
            "hypothesis": "Does the inclusion of the RsCIN module, especially with a multi-window mask strategy, improve anomaly detection performance compared to using a single-window operation or no re-scoring with constrained image-level neighborhood?",
            "method": "Conduct controlled experiments by evaluating the MuSc method under different settings: (1) without the RsCIN module, (2) with the RsCIN module using a single-window mask strategy (using window sizes k \u2208 {2,...,9} and full-window k = \u221e), and (3) with the proposed multi-window mask strategy. Run these configurations on both MVTec AD and VisA datasets. Measure classification metrics (F1-max score, AUROC) and segmentation metrics (such as pixel-AUROC, PRO segmentation scores, and others provided in Table 17). Additionally, consider the effect of varying the number of reference images and dataset splits (as detailed in Table 7) and analyze the influence of different window mask sizes (refer to Figures 7 and 8). Compare improvements when integrating the RsCIN module in other AC/AS methods as discussed in Appendix A.2.4.",
            "expected_outcome": "The RsCIN module is expected to improve anomaly detection performance, demonstrating an approximate 0.9% gain in F1-max score on MVTec AD and a 2.8% AUROC gain on VisA. The multi-window strategy should further outperform the single-window mask operation and the configuration without RsCIN, with additional improvements in segmentation metrics such as pixel-AUROC and PRO segmentation scores, as supported by quantitative results in Tables 6, 7, and 17.",
            "subsection_source": "4.2 A BLATION STUDY"
        },
        {
            "hypothesis": "Does dividing the entire test dataset into smaller subsets (controlled by s) significantly reduce per-image inference time and GPU memory cost without notably compromising the AC and AS performance? Given the detailed results in Table 6 and Table 7, the experiment seeks to validate whether increasing s (i.e., creating smaller subsets per evaluation) leads to a decrease in computational resources (e.g., from 998.8 ms and 7168 MB at s=1 to 513.5 ms and 5026 MB at s=3) with only a minor degradation in detection performance (e.g., a drop in AC of less than 1.1% and a nearly invariant AS) on the MVTec AD and VisA datasets.",
            "method": "Divide the test images into different numbers of subsets (s = 1, 2, 3), following the division strategy reported in the original work. For each grouping, measure the per-image inference time and maximum GPU memory cost using an NVIDIA RTX 3090 GPU, referring to the values reported in Table 6. Simultaneously, evaluate the anomaly detection metrics, specifically the AC (image-level anomaly detection) and AS (pixel-level anomaly segmentation) scores, on both the MVTec AD and VisA datasets as detailed in Table 7. Include comparison of the time and memory trade-offs alongside the observed minor variations in the performance metrics across the different subset configurations.",
            "expected_outcome": "It is expected that increasing s will lead to a significant reduction in both inference time and GPU memory cost (e.g., decreasing from 998.8 ms and 7168 MB at s=1 to 513.5 ms and 5026 MB at s=3). The AC metric is anticipated to drop slightly (by less than 1.1%) while the AS metric will remain almost constant (down by at most 0.2%). This indicates that the efficiency gains in computation come at a minimal cost to overall detection performance.",
            "subsection_source": "4.2 A BLATION STUDY"
        }
    ],
    "follow_up_work_ideas": [
        {
            "idea": "Investigate the impact of varying the number of reference images in the MuSc+ variant on classification and segmentation performance.",
            "experiment_design": "Design an experiment where the number of reference images is systematically varied (for example, using different counts such as 1, 4, 8, 16, etc.). For each configuration, evaluate the model's classification and segmentation metrics on both MVTec AD and VisA datasets. Track computational costs such as per-image inference time and GPU memory usage, and compare the results to identify the optimal trade-off between performance improvement and resource consumption.",
            "subsection_source": "4.1 Q UANTITATIVE AND QUALITATIVE RESULTS"
        },
        {
            "idea": "Evaluate the robustness of MuSc under various real-world perturbations such as inconsistent image orientations, scales, and noise.",
            "experiment_design": "Extend the current experimental setup by artificially introducing variations such as rotations, scaling changes, and noise to the test images. Run the MuSc model as well as other comparative methods (e.g., WinCLIP, APRIL-GAN) on these perturbed datasets. Record the standard anomaly detection metrics (AUROC, F1-max, AP, and PRO) and analyze the sensitivity of each model to these perturbations. This would help in understanding the generalizability and robustness of MuSc in real industrial scenarios.",
            "subsection_source": "4.1 Q UANTITATIVE AND QUALITATIVE RESULTS"
        },
        {
            "idea": "Extend the analysis of aggregation degrees by exploring a wider range of r values beyond those initially tested.",
            "experiment_design": "Conduct experiments on both MVTec AD and VisA with r values including extremes (e.g., r = 0, 2, 4, 6, 8) to observe the performance trend in finer granularity. This could help in understanding the sensitivity of LNAMD to local neighborhood size and possibly lead to dynamically adapting r based on input image characteristics.",
            "subsection_source": "4.2 A BLATION STUDY"
        },
        {
            "idea": "Investigate the applicability of the MuSc method with the RsCIN module on larger-scale, real-world industrial datasets with more diverse anomaly types.",
            "experiment_design": "Apply the MuSc pipeline to an industrial dataset that includes a broader variety of anomalies and image resolutions. Compare performance metrics and computational efficiency against baseline methods. Additionally, assess if the minor performance gains from the RsCIN module are consistent in this new domain and whether any adaptation (e.g., window mask size adjustments) is beneficial.",
            "subsection_source": "4.2 A BLATION STUDY"
        },
        {
            "idea": "Analyze the impact of incorporating few-shot settings more extensively, particularly on domains where the prior information in unlabeled images might be limited.",
            "experiment_design": "Design experiments where a varying number of labeled normal reference images are incrementally added to the zero-shot MuSc framework. Perform evaluations on datasets with limited normal prior information to determine if few-shot extensions can lead to significant improvements, and compare the results against both the standard MuSc and other few-shot anomaly detection methods.",
            "subsection_source": "4.2 A BLATION STUDY"
        }
    ],
    "main_takeaways": [
        "The paper proposes the MuSc method (and its variant MuSc+) that achieves competitive anomaly segmentation and classification performance on benchmarks such as MVTec AD and VisA.",
        "Inference time and GPU memory cost can be significantly reduced by partitioning the dataset into multiple subsets (e.g., using s=3 reduces inference time to 513.5 ms and GPU cost to 5026 MB compared to s=1).",
        "The method shows robustness against inconsistent orientations and scales, outperforming existing methods like WinCLIP and APRIL-GAN in these settings, despite using a fixed pre-trained vision transformer that only performs minor data augmentations.",
        "The choice of configuration parameters, such as the proportion of the minimum value interval in MSM and the window mask sizes (with or without the RsCIN module), has a measurable impact on performance metrics (e.g., slight changes in AUROC, F1-max scores).",
        "Incorporating additional components like re-scoring with a constrained image-level neighborhood (RsCIN) and increasing the number of reference images can improve classification and segmentation results."
    ]
}