{
  "requirements": [
    "Step 1: Set up the environment and import necessary libraries for deep learning, data handling, and visualization (/workspace/video_prediction/tools/non_dist_train.py:3-8)",
    "Step 2: Create a parser to handle command-line arguments for model configuration, training parameters, and dataset options (/workspace/video_prediction/simvp/utils/parser.py:6-82)",
    "Step 3: Load the Moving MNIST dataset, which contains sequences of moving digits (/workspace/video_prediction/simvp/datasets/dataloader_moving_mnist.py:9-176)",
    "Step 4: Split each video sequence into input frames (observed sequence) and target frames (future sequence to predict) (/workspace/video_prediction/simvp/datasets/dataloader_moving_mnist.py:139-147)",
    "Step 5: Configure the SimVP model with MogaNet as the backbone by setting model_type to 'moga' (/workspace/video_prediction/configs/mmnist/simvp/SimVP_MogaNet.py:1-14)",
    "Step 6: Build the SimVP model architecture with encoder, hidden translator (MogaNet), and decoder components (/workspace/video_prediction/simvp/models/simvp_model.py:9-49)",
    "Step 7: Implement the MogaNet blocks with Multi-Order Gated Aggregation for the hidden translator (/workspace/video_prediction/simvp/modules/layers/moganet.py:98-140)",
    "Step 8: Initialize the training experiment with the configured model and dataset (/workspace/video_prediction/simvp/api/train.py:24-68)",
    "Step 9: Train the model to predict future frames based on observed frames using MSE loss (/workspace/video_prediction/simvp/methods/simvp.py:51-78)",
    "Step 10: Validate the model during training by comparing predicted frames with ground truth (/workspace/video_prediction/simvp/methods/simvp.py:80-102)",
    "Step 11: Test the trained model on the test dataset and compute evaluation metrics (/workspace/video_prediction/simvp/api/train.py:191-211)",
    "Final Step: Save and visualize the results by displaying input sequence, predicted future frames, and ground truth future frames (/workspace/video_prediction/simvp/api/train.py:206-211)"
  ],
  "agent_instructions": "Your task is to implement a video prediction system using the SimVP (Simple Video Prediction) model with MogaNet as the backbone to predict future frames in a Moving MNIST video sequence.\n\n1. Dataset Setup:\n   - Use the Moving MNIST dataset, which contains sequences of moving digits\n   - Each sequence should be split into input frames (observed sequence) and target frames (future sequence to predict)\n   - Configure the data loader to handle the appropriate sequence lengths\n\n2. Model Architecture:\n   - Implement the SimVP model with three main components:\n     a. Encoder: Converts input frames into latent representations\n     b. Hidden translator: Uses MogaNet blocks to process temporal information\n     c. Decoder: Reconstructs the predicted future frames from latent representations\n   - Configure the model with MogaNet as the backbone by setting model_type to 'moga'\n   - The MogaNet backbone should use Multi-Order Gated Aggregation for spatial feature extraction\n\n3. Training Process:\n   - Train the model to predict future frames based on observed frames\n   - Use MSE (Mean Squared Error) loss to measure the difference between predicted and ground truth frames\n   - Implement a validation process to monitor the model's performance during training\n   - Use appropriate learning rate scheduling (e.g., onecycle) to optimize training\n\n4. Evaluation:\n   - Test the trained model on a separate test dataset\n   - Compute evaluation metrics such as MSE and MAE to quantify prediction accuracy\n   - Visualize the results by displaying the input sequence, predicted future frames, and ground truth future frames side by side\n\n5. Key Configuration Parameters:\n   - Configure hidden dimensions for spatial and temporal features\n   - Set appropriate number of layers for the model\n   - Use a suitable learning rate and batch size for training\n\nThe goal is to create a model that can accurately predict the continued movement of digits in the video sequence, maintaining both the appearance of the digits and their motion patterns."
}