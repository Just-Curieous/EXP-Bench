{
    "source": ["/workspace/train.py", "/workspace/validate.py"],
    "usage_instructions": "To evaluate whether scaling up MogaNet models (MogaNet-S, MogaNet-B/L) yields superior or competitive performance compared to state-of-the-art architectures under similar computational budgets, follow these steps:\n\n1. First, train the scaled-up MogaNet models on ImageNet-1K using the standard 300-epoch training regimen with AdamW optimizer (learning rate 1e-3) and a cosine learning rate scheduler:\n\n   For MogaNet-S:\n   ```\n   python -m torch.distributed.launch --nproc_per_node=8 train.py \\\n   --model moganet_small --img_size 224 --drop_path 0.1 \\\n   --epochs 300 --batch_size 128 --lr 1e-3 --weight_decay 0.05 \\\n   --crop_pct 0.9 --min_lr 1e-5 \\\n   --model_ema --model_ema_decay 0.9999 \\\n   --data_dir /path/to/imagenet-1k \\\n   --experiment /path/to/save_results\n   ```\n\n   For MogaNet-B:\n   ```\n   python -m torch.distributed.launch --nproc_per_node=8 train.py \\\n   --model moganet_base --img_size 224 --drop_path 0.2 \\\n   --epochs 300 --batch_size 128 --lr 1e-3 --weight_decay 0.05 \\\n   --crop_pct 0.9 --min_lr 1e-5 \\\n   --model_ema --model_ema_decay 0.9999 \\\n   --data_dir /path/to/imagenet-1k \\\n   --experiment /path/to/save_results\n   ```\n\n   For MogaNet-L:\n   ```\n   python -m torch.distributed.launch --nproc_per_node=8 train.py \\\n   --model moganet_large --img_size 224 --drop_path 0.3 \\\n   --epochs 300 --batch_size 128 --lr 1e-3 --weight_decay 0.05 \\\n   --crop_pct 0.9 --min_lr 1e-5 \\\n   --model_ema --model_ema_decay 0.9999 \\\n   --data_dir /path/to/imagenet-1k \\\n   --experiment /path/to/save_results\n   ```\n\n2. After training, evaluate the models using the validate.py script to measure top-1 accuracy:\n\n   For MogaNet-S:\n   ```\n   python validate.py \\\n   --model moganet_small --img_size 224 --crop_pct 0.9 --num_gpu 8 --use_ema \\\n   --data_dir /path/to/imagenet-1k \\\n   --checkpoint /path/to/checkpoint.tar.gz\n   ```\n\n   For MogaNet-B:\n   ```\n   python validate.py \\\n   --model moganet_base --img_size 224 --crop_pct 0.9 --num_gpu 8 --use_ema \\\n   --data_dir /path/to/imagenet-1k \\\n   --checkpoint /path/to/checkpoint.tar.gz\n   ```\n\n   For MogaNet-L:\n   ```\n   python validate.py \\\n   --model moganet_large --img_size 224 --crop_pct 0.9 --num_gpu 8 --use_ema \\\n   --data_dir /path/to/imagenet-1k \\\n   --checkpoint /path/to/checkpoint.tar.gz\n   ```\n\n3. To measure computational metrics (parameter count and FLOPs), use the get_flops.py script:\n   ```\n   python get_flops.py --model moganet_small\n   python get_flops.py --model moganet_base\n   python get_flops.py --model moganet_large\n   ```\n\n4. Compare the results with state-of-the-art architectures like Swin-T, ConvNeXt-T, HorNet-S/B, and SLaK-S/B. The README.md file already contains a table with the results showing that MogaNet-S achieves 83.4% top-1 accuracy, outperforming Swin-T and ConvNeXt-T by margins of 2.1 and 1.2 percentage points respectively. The TRAINING.md file also contains comprehensive comparison tables with other architectures."
}