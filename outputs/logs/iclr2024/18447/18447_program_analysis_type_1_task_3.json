{
  "requirements": [
    "Step 1: Set up the training environment by configuring distributed training, AMP (Automatic Mixed Precision), and random seed (/workspace/train.py:332-378)",
    "Step 2: Create the MogaNet-tiny model with specified parameters (image size, drop path rate) (/workspace/train.py:380-396)",
    "Step 3: Calculate and log model FLOPs and parameter count (/workspace/train.py:398-404)",
    "Step 4: Configure data loading parameters based on model requirements (/workspace/train.py:406-407)",
    "Step 5: Move model to GPU and configure memory format if needed (/workspace/train.py:419-422)",
    "Step 6: Set up synchronized batch normalization for distributed training if specified (/workspace/train.py:425-436)",
    "Step 7: Create optimizer with specified learning rate and weight decay (/workspace/train.py:443)",
    "Step 8: Configure AMP (mixed precision) settings based on availability (/workspace/train.py:446-460)",
    "Step 9: Set up learning rate scheduler (cosine or step) with specified parameters (/workspace/train.py:497-508)",
    "Step 10: Create training and validation datasets from ImageNet (/workspace/train.py:511-521)",
    "Step 11: Configure data augmentation including mixup if specified (/workspace/train.py:523-541)",
    "Step 12: Create data loaders with specified batch size and augmentation parameters (/workspace/train.py:547-594)",
    "Step 13: Set up loss function with label smoothing (/workspace/train.py:596-614)",
    "Step 14: Configure checkpoint saving and experiment tracking (/workspace/train.py:616-637)",
    "Step 15: Train the model for specified number of epochs, running validation after each epoch (/workspace/train.py:639-686)",
    "Step 16: For each epoch, train one epoch by iterating through batches, computing loss, and updating model parameters (/workspace/train.py:688-806)",
    "Step 17: After each epoch, validate the model on the validation set and compute accuracy metrics (/workspace/train.py:825-887)",
    "Step 18: Save the best model checkpoint based on validation accuracy (/workspace/train.py:677-680)",
    "Final Step: Compare the training logs and validation results between different configurations to observe differences in convergence speed and final top-1 accuracy (/workspace/train.py:684-685)"
  ],
  "agent_instructions": "Create a script to train and evaluate MogaNet-tiny models on ImageNet with different configurations. The script should:\n\n1. Support distributed training across multiple GPUs using PyTorch's distributed data parallel\n2. Implement two training configurations:\n   - Base configuration: 224x224 resolution with cosine learning rate scheduler\n   - Refined configuration: 256x256 resolution with step learning rate scheduler\n\nFor both configurations, the script should:\n- Load and prepare the ImageNet dataset with appropriate data augmentation\n- Create a MogaNet-tiny model with appropriate parameters\n- Set up mixed precision training using AMP\n- Configure the optimizer (AdamW) with appropriate learning rate and weight decay\n- Implement the specified learning rate scheduler (cosine or step)\n- Train for 300 epochs with a batch size of 128\n- Apply data augmentation including mixup (0.1), AutoAugment, and center crop (90%)\n- Save checkpoints during training, including the best model based on validation accuracy\n- Implement a validation function to evaluate the model on the validation set\n- Log training and validation metrics\n\nThe script should allow specifying command-line arguments for:\n- Model architecture (moganet_tiny)\n- Image size (224 or 256)\n- Drop path rate (0.1)\n- Learning rate (1e-3 or 2e-3)\n- Weight decay (0.04)\n- Scheduler type (cosine or step)\n- Decay epochs and rate for step scheduler\n- Data augmentation parameters\n- Path to ImageNet data\n- Output directory for saving results\n\nAfter training, implement a validation script that can load a trained checkpoint and evaluate its performance on the ImageNet validation set.",
  "masked_source": [
    "/workspace/train.py"
  ]
}