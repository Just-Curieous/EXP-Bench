{
    "source": ["/workspace/train.py"],
    "usage_instructions": "To compare MogaNet-T with different input resolutions and training configurations, run the following two commands:\n\n1. For the baseline (224x224 resolution with standard settings):\n```\npython -m torch.distributed.launch --nproc_per_node=8 train.py \\\n--model moganet_tiny --img_size 224 --drop_path 0.1 \\\n--epochs 300 --batch_size 128 --lr 1e-3 --weight_decay 0.04 \\\n--sched cosine --aa rand-m7-mstd0.5-inc1 --crop_pct 0.9 --mixup 0.1 \\\n--amp --native_amp \\\n--data_dir /path/to/imagenet-1k \\\n--experiment /path/to/save_results_224\n```\n\n2. For the refined settings (256x256 resolution with optimized scheduler):\n```\npython -m torch.distributed.launch --nproc_per_node=8 train.py \\\n--model moganet_tiny --img_size 256 --drop_path 0.1 \\\n--epochs 300 --batch_size 128 --lr 2e-3 --weight_decay 0.04 \\\n--sched step --decay-epochs 30 60 90 --decay-rate 0.1 \\\n--aa rand-m7-mstd0.5-inc1 --crop_pct 0.9 --mixup 0.1 \\\n--amp --native_amp \\\n--data_dir /path/to/imagenet-1k \\\n--experiment /path/to/save_results_256\n```\n\nAfter training, you can validate the models using:\n```\npython validate.py \\\n--model moganet_tiny --img_size 224 --crop_pct 0.9 \\\n--data_dir /path/to/imagenet-1k \\\n--checkpoint /path/to/save_results_224/model_best.pth.tar\n```\n\nAnd:\n```\npython validate.py \\\n--model moganet_tiny --img_size 256 --crop_pct 0.9 \\\n--data_dir /path/to/imagenet-1k \\\n--checkpoint /path/to/save_results_256/model_best.pth.tar\n```\n\nCompare the training logs and validation results to observe the differences in convergence speed and final top-1 accuracy."
}