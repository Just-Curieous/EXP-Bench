{
  "requirements": [
    "Step 1: Create a custom HTTP agent class that inherits from the AgentClient base class (/workspace/src/client/agents/http_agent.py:164-184)",
    "Step 2: Initialize the agent with necessary parameters including URL, headers, body, return format, and prompter (/workspace/src/client/agents/http_agent.py:165-183)",
    "Step 3: Implement a method to handle conversation history using the prompter (/workspace/src/client/agents/http_agent.py:185-186)",
    "Step 4: Implement the inference method that sends requests to the LLM API with proper error handling and retries (/workspace/src/client/agents/http_agent.py:188-215)",
    "Step 5: Create a prompter class or use existing prompters to format conversation history according to the API's requirements (/workspace/src/client/agents/http_agent.py:46-136)",
    "Step 6: Implement context limit detection to handle API limitations (/workspace/src/client/agents/http_agent.py:138-161)",
    "Step 7: Create a configuration file for the agent with URL, headers, body parameters, prompter settings, and return format (/workspace/configs/agents/openai-chat.yaml:1-13)",
    "Step 8: Register the agent in a configuration file with specific model parameters (/workspace/configs/agents/api_agents.yaml:1-23)",
    "Final Step: Test the agent using the agent_test.py script to verify it can process conversation history and generate responses (/workspace/src/client/agent_test.py:15-32)"
  ],
  "agent_instructions": "Your task is to implement a custom HTTP-based agent in AgentBench that can connect to different LLM APIs. This agent should be able to process conversation history and handle API responses appropriately. Follow these steps:\n\n1. Create an HTTP agent class that inherits from the AgentClient base class. This class should:\n   - Accept parameters for API configuration (URL, headers, body parameters)\n   - Handle formatting of conversation history\n   - Process API responses\n   - Implement error handling and retries\n\n2. Implement a prompter system that can format conversation history according to different API requirements. The prompter should:\n   - Convert conversation history into the format expected by the API\n   - Support different message formats (role-content dictionaries, prompt strings, etc.)\n   - Be configurable for different LLM APIs\n\n3. Create a configuration system for the agent that includes:\n   - API endpoint URL\n   - Authentication headers\n   - Request body parameters\n   - Response parsing format\n   - Prompter configuration\n\n4. Implement error handling for common API issues:\n   - Context length limitations\n   - Network errors\n   - API-specific error responses\n   - Implement a retry mechanism for transient errors\n\n5. Create a registration system for different LLM API configurations that allows:\n   - Defining model-specific parameters\n   - Inheriting from base configurations\n   - Overriding specific parameters\n\n6. Test your implementation with different LLM APIs to ensure it can properly:\n   - Format conversation history according to each API's requirements\n   - Send requests with proper authentication\n   - Parse responses correctly\n   - Handle errors gracefully\n\nYour implementation should be flexible enough to work with various LLM APIs (like OpenAI, Claude, etc.) by simply changing the configuration without modifying the core code."
}