{
    "source": [
        "/workspace/create_poisoned_set_imagenet.py",
        "/workspace/other_defense.py"
    ],
    "usage_instructions": "To evaluate BaDExpert's generalization on ImageNet across multiple model architectures (ResNet18, ResNet101, ViT-B/16), follow these steps:\n\n1. First, create a poisoned ImageNet dataset for each attack type you want to evaluate:\n   ```bash\n   # Create poisoned datasets for different attack types\n   python create_poisoned_set_imagenet.py -poison_type badnet -poison_rate 0.003\n   python create_poisoned_set_imagenet.py -poison_type blend -poison_rate 0.003\n   python create_poisoned_set_imagenet.py -poison_type trojan -poison_rate 0.003\n   ```\n\n2. For each model architecture and poisoned dataset, modify the architecture in config.py by changing line 93 to the desired model:\n   - For ResNet18 (default): `'imagenet' : torchvision.models.resnet18,`\n   - For ResNet101: `'imagenet' : torchvision.models.resnet101,`\n   - For ViT-B/16: `'imagenet' : torchvision.models.vit_b_16,`\n\n3. Run BaDExpert defense on each poisoned dataset and model architecture:\n   ```bash\n   # Example for ResNet18 with BadNet attack\n   python other_defense.py -dataset imagenet -poison_type badnet -poison_rate 0.003 -defense BaDExpert\n   \n   # Example for ResNet18 with Blend attack\n   python other_defense.py -dataset imagenet -poison_type blend -poison_rate 0.003 -defense BaDExpert\n   \n   # Example for ResNet18 with TrojanNN attack\n   python other_defense.py -dataset imagenet -poison_type trojan -poison_rate 0.003 -defense BaDExpert\n   ```\n\n4. Repeat step 3 for each model architecture by modifying config.py between runs.\n\nThe output will include comprehensive metrics such as AUROC, ASR, and Clean Accuracy (CA) for each configuration. The results can be found in the logs directory and can be consolidated into tables similar to those in the paper."
}