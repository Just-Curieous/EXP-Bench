{
    "source": ["/workspace/egs/librispeech/ASR/zipformer/train.py", "/workspace/egs/librispeech/ASR/zipformer/decode.py"], 
    "usage_instructions": "To run the experiment comparing Zipformer-M with and without temporal downsampling:\n\n1. First, train the baseline Zipformer-M model with temporal downsampling (this is the default configuration):\n\nexport CUDA_VISIBLE_DEVICES=\"0,1,2,3\"\n./zipformer/train.py \\\n  --world-size 4 \\\n  --num-epochs 50 \\\n  --start-epoch 1 \\\n  --use-fp16 1 \\\n  --exp-dir zipformer/exp-baseline \\\n  --full-libri 1 \\\n  --max-duration 1000\n\n2. Then, train the modified Zipformer-M model without temporal downsampling by setting all downsampling factors to 1:\n\nexport CUDA_VISIBLE_DEVICES=\"0,1,2,3\"\n./zipformer/train.py \\\n  --world-size 4 \\\n  --num-epochs 50 \\\n  --start-epoch 1 \\\n  --use-fp16 1 \\\n  --exp-dir zipformer/exp-no-downsampling \\\n  --full-libri 1 \\\n  --max-duration 1000 \\\n  --downsampling-factor \"1,1,1,1,1,1\"\n\n3. After training, evaluate both models on the LibriSpeech test-clean and test-other sets:\n\nexport CUDA_VISIBLE_DEVICES=\"0\"\n./zipformer/decode.py \\\n  --epoch 50 \\\n  --avg 10 \\\n  --exp-dir zipformer/exp-baseline \\\n  --max-duration 600\n\nexport CUDA_VISIBLE_DEVICES=\"0\"\n./zipformer/decode.py \\\n  --epoch 50 \\\n  --avg 10 \\\n  --exp-dir zipformer/exp-no-downsampling \\\n  --max-duration 600 \\\n  --downsampling-factor \"1,1,1,1,1,1\"\n\nThe results should confirm the hypothesis that removing temporal downsampling increases the model parameters (from 65.6M to approximately 94.2M) and leads to a slight degradation in performance, with test-clean WER increasing from around 2.21% to 2.23% and test-other WER increasing from 4.79% to 5.09%."
}