{
  "questions": [
    {
      "hypothesis": "Will TopoMLP outperform existing state-of-the-art models (STSU, VectorMapNet, MapTR, TopoNet) on the OpenLane-V2 datasets using the ResNet-50 backbone?",
      "method": "Design two experiments using the OpenLane-V2 dataset: one on subset A (as presented in Table 1) and one on subset B (as in Table 2). For both experiments, use TopoMLP with a ResNet-50 backbone and follow the documented training protocol (e.g., 24 epochs, standard image resizing and augmentation, fixed region settings, and a batch size of 8). Compute metrics including OLS, TOP_ll, TOP_lt, DET_l, and DET_t. Directly compare the obtained values with the reported figures for the state-of-the-art methods (for example, on subset A, expect OLS = 38.2, TOP_ll = 7.2, TOP_lt = 22.8 and on subset B, noticeable improvements over TopoNet such as TOP_ll = 7.6 vs. 2.5).",
      "expected_outcome": "Based on the paper\u2019s results, TopoMLP should achieve higher overall performance, particularly with superior topology reasoning accuracy. The experiment is expected to validate that TopoMLP outperforms STSU, VectorMapNet, MapTR, and TopoNet on both subsets under the same backbone conditions.",
      "subsection_source": "4.3 S TATE -OF-THE-ART COMPARISON",
      "source": [
        "/workspace/tools/dist_train.sh",
        "/workspace/tools/dist_test.sh",
        "/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py",
        "/workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py"
      ],
      "usage_instructions": "For Experiment 1 (OpenLane-V2 subset A): First train the model using `./tools/dist_train.sh projects/configs/topomlp_setA_r50_wo_yolov8.py 8 --work-dir=./work_dirs/topomlp_setA_r50_wo_yolov8` (adjust the number of GPUs as needed). After training completes, evaluate the model using `./tools/dist_test.sh projects/configs/topomlp_setA_r50_wo_yolov8.py ./work_dirs/topomlp_setA_r50_wo_yolov8/latest.pth 8 --eval=bbox`. For Experiment 2 (OpenLane-V2 subset B): Follow the same procedure but use the subset B configuration files: `./tools/dist_train.sh projects/configs/topomlp_setB_r50_wo_yolov8.py 8 --work-dir=./work_dirs/topomlp_setB_r50_wo_yolov8` for training and `./tools/dist_test.sh projects/configs/topomlp_setB_r50_wo_yolov8.py ./work_dirs/topomlp_setB_r50_wo_yolov8/latest.pth 8 --eval=bbox` for evaluation. The configuration files already use ResNet-50 backbone and follow the documented training protocol with 24 epochs. The evaluation will compute the required metrics (OLS, TOP_ll, TOP_lt, DET_l, and DET_t) which can be compared with the state-of-the-art methods as shown in the training_inference.md documentation.",
      "requirements": [
        "Step 1: Parse command line arguments for distributed training including configuration file path, number of GPUs, and additional parameters (/workspace/tools/dist_train.sh:3-8)",
        "Step 2: Set up the distributed training environment with PyTorch's distributed module, configuring node count, rank, master address, and processes per node (/workspace/tools/dist_train.sh:10-16)",
        "Step 3: Launch the training script with the parsed configuration and additional parameters (/workspace/tools/dist_train.sh:17-20)",
        "Step 4: Parse command line arguments for distributed testing including configuration file path, checkpoint path, number of GPUs, and additional parameters (/workspace/tools/dist_test.sh:3-9)",
        "Step 5: Set up the distributed testing environment with PyTorch's distributed launch module, configuring node count, rank, master address, and processes per node (/workspace/tools/dist_test.sh:11-17)",
        "Step 6: Launch the testing script with the parsed configuration, checkpoint path, and additional parameters (/workspace/tools/dist_test.sh:18-22)",
        "Step 7: Configure the TopoMLP model architecture with ResNet-50 backbone, Feature Pyramid Network neck, and specialized heads for lane detection, traffic element detection, and topology modeling (/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py:10-192, /workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py:10-192)",
        "Step 8: Define data preprocessing pipelines for training and testing, including image loading, normalization, resizing, and formatting (/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py:196-245, /workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py:196-245)",
        "Step 9: Configure dataset settings for either OpenLane-V2 subset A or subset B, specifying data paths and collection names (/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py:247-279, /workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py:247-279)",
        "Step 10: Set up optimizer with AdamW, learning rate of 2e-4, and weight decay of 1e-2, with reduced learning rate for backbone (/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py:281-289, /workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py:281-289)",
        "Step 11: Configure learning rate schedule with cosine annealing policy, linear warmup, and specific warmup parameters (/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py:291-296, /workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py:291-296)",
        "Step 12: Set training to run for 24 epochs with evaluation at the end (/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py:298-299, /workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py:298-299)",
        "Final Step: Evaluate the model using the bbox metric to compute OLS, TOP_ll, TOP_lt, DET_l, and DET_t metrics for comparison with state-of-the-art methods (/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py:299, /workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py:299)"
      ],
      "agent_instructions": "Your task is to implement scripts for training and evaluating a topology-aware multi-lane perception model (TopoMLP) on the OpenLane-V2 dataset. You need to create:\n\n1. A distributed training script that:\n   - Takes a configuration file path, number of GPUs, and optional additional parameters\n   - Sets up a PyTorch distributed training environment\n   - Launches the training process with the specified configuration\n\n2. A distributed testing script that:\n   - Takes a configuration file path, checkpoint path, number of GPUs, and optional additional parameters\n   - Sets up a PyTorch distributed testing environment\n   - Launches the evaluation process with the specified configuration and checkpoint\n\n3. Configuration files for two experiments:\n   - One for OpenLane-V2 subset A\n   - One for OpenLane-V2 subset B\n\nEach configuration file should define:\n   - A TopoMLP model with ResNet-50 backbone and Feature Pyramid Network\n   - Specialized heads for lane detection, traffic element detection, and topology modeling\n   - Data preprocessing pipelines for training and testing\n   - Dataset settings for the appropriate OpenLane-V2 subset\n   - Optimization settings using AdamW with learning rate 2e-4 and weight decay 1e-2\n   - Learning rate schedule with cosine annealing and linear warmup\n   - Training for 24 epochs with evaluation at the end\n\nThe model should be evaluated using the bbox metric to compute OLS, TOP_ll, TOP_lt, DET_l, and DET_t metrics for comparison with state-of-the-art methods.\n\nThe training should be launched with 8 GPUs (adjustable) and results should be saved to a work directory specific to each experiment.",
      "masked_source": [
        "/workspace/tools/dist_train.sh",
        "/workspace/tools/dist_test.sh",
        "/workspace/projects/configs/topomlp_setA_r50_wo_yolov8.py",
        "/workspace/projects/configs/topomlp_setB_r50_wo_yolov8.py"
      ]
    }
  ]
}